---
layout: icml26
title: "AI Scientist Competition"
permalink: /icml26/competition
---

# AI Scientist Competition

AI has shifted from passive assistant to active agent: systems now generate hypotheses, design experiments, orchestrate robots, and draft papers. The **AI Scientist Competition** focuses exclusively on these autonomous or semi-autonomous scientific systems. (If you are proposing a dataset, please visit the [Dataset Competition page](/icml26/dataset.html).)

Winning AI Scientist proposals share **$10K in prizes sponsored by Xaira Therapeutics**, present during the workshop, and help shape emerging benchmarks and governance for trustworthy AI-driven discovery.

## What to Include
- **Scope & autonomy:** Explain which stages of the scientific workflow (ideation, planning, simulation, execution, analysis, writing) your system covers and how decisions are made.
- **Architecture & tooling:** Describe model components, agent orchestration, retrieval or tool use, robotic integrations, and human oversight checkpoints.
- **Evaluation roadmap:** Provide benchmarks, metrics, ablation plans, or verification procedures that demonstrate novelty, robustness, and trustworthiness.
- **Governance & safeguards:** Detail how you manage safety, privacy, biosafety, or dual-use risks, and how attribution/credit is recorded for human collaborators.

## Submission Guidelines
- **Length:** 2 pages of main text (PDF) with unlimited references/appendices.
- **Format:** ICML 2026 style file (double-blind option). Update the template footnote to “Submitted to the AI for Science workshop (ICML 2026).”
- **Anonymity:** Fully double blind. Remove identifiable metadata, URLs, or repositories.
- **Submission Portal:** [OpenReview](https://openreview.net/group?id=ICML.cc/2026/Workshop/AI4Science) → AI Scientist Competition.
- **Review:** At least two expert reviewers plus an area chair; top proposals earn spotlight talks and prize consideration.

## Evaluation Criteria
1. **Scientific ambition & coverage** of the end-to-end discovery pipeline.
2. **Technical feasibility** of algorithms, agents, and hardware/software integrations.
3. **Evaluation rigor** (benchmarks, metrics, reproducibility).
4. **Safety, governance, and transparency** (documentation, provenance, alignment with policies).
5. **Potential impact** on real labs or cross-domain collaborations.

## Timeline (Anywhere on Earth)
- Abstract deadline: **April 21, 2026**
- Submission deadline: **April 24, 2026**
- Notification: **May 15, 2026**
- Camera-ready / spotlight materials: **May 29, 2026**
- Live spotlights: **Workshop day at ICML 2026 (July, exact date TBA)**

Questions? Email [ai4sciencecommunity@gmail.com](mailto:ai4sciencecommunity@gmail.com). If you need introductions to collaborators (e.g., robotics labs or evaluation partners), reach out early so we can help.
